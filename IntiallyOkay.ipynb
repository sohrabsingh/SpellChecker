{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1345fb40-6f07-420e-895d-847f40f14e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1aab36f88f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# Cell 1: Imports & Setup\n",
    "# ------------------------------\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "427962b7-f057-4767-bc5e-e89a85f67bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "CUDA device: NVIDIA GeForce RTX 3050 4GB Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# Cell 2: Device detection\n",
    "# ------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "if device.type == \"cuda\":\n",
    "    print(\"CUDA device:\", torch.cuda.get_device_name(0))\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10387171-93ef-4de6-939f-116738acb868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Cell 3: Paths & folders\n",
    "# ------------------------------\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "os.makedirs(\"vocab\", exist_ok=True)\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "CORPUS_PATH = \"data/all_hindi_clean.txt\"\n",
    "DATA_PAIRS_PATH = \"data/data_pairs.pkl\"\n",
    "VOCAB_PATH = \"vocab/hindi_vocab_100k.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d2b769c-2130-4916-b32d-fcc2eb2e2b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50000 sentences (limited to 50000)\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# Cell 4: Load corpus\n",
    "# ------------------------------\n",
    "MAX_LINES = 50000  # limit\n",
    "\n",
    "if not os.path.exists(CORPUS_PATH):\n",
    "    raise FileNotFoundError(f\"Corpus not found at {CORPUS_PATH}\")\n",
    "\n",
    "sentences = []\n",
    "with open(CORPUS_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= MAX_LINES:\n",
    "            break\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            sentences.append(line)\n",
    "\n",
    "print(f\"Loaded {len(sentences)} sentences (limited to {MAX_LINES})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7448a4d8-a565-4717-927a-270681e88813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Cell 5: Create typos function\n",
    "# ------------------------------\n",
    "def create_typos(sentence, typo_prob=0.2):\n",
    "    words = sentence.split()\n",
    "    new_words = []\n",
    "    for w in words:\n",
    "        if random.random() < typo_prob:\n",
    "            typo_type = random.choice([\"delete\", \"replace\", \"transpose\"])\n",
    "            if typo_type == \"delete\" and len(w) > 1:\n",
    "                i = random.randint(0, len(w)-1)\n",
    "                w = w[:i] + w[i+1:]\n",
    "            elif typo_type == \"replace\" and len(w) > 0:\n",
    "                i = random.randint(0, len(w)-1)\n",
    "                w = w[:i] + random.choice(list(w)) + w[i+1:]\n",
    "            elif typo_type == \"transpose\" and len(w) > 1:\n",
    "                i = random.randint(0, len(w)-2)\n",
    "                w = w[:i] + w[i+1] + w[i] + w[i+2:]\n",
    "        new_words.append(w)\n",
    "    return \" \".join(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "564588b9-c456-4853-99a2-62f3be45c6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample pair: ('के', 'के')\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# Cell 6: Create dataset pairs\n",
    "# ------------------------------\n",
    "data_pairs = [(create_typos(s), s) for s in sentences]\n",
    "print(\"Sample pair:\", data_pairs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45575110-dd19-4d5c-9f6e-ecd0f5e66004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 44310\n",
      "Vocabulary saved!\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# Cell 7: Build vocabulary\n",
    "# ------------------------------\n",
    "word_counter = Counter()\n",
    "for _, target in data_pairs:\n",
    "    word_counter.update(target.split())\n",
    "\n",
    "PAD, SOS, EOS, UNK = \"<PAD>\", \"<SOS>\", \"<EOS>\", \"<UNK>\"\n",
    "\n",
    "vocab = {PAD:0, SOS:1, EOS:2, UNK:3}\n",
    "top_k = 100000\n",
    "for word, _ in word_counter.most_common(top_k):\n",
    "    if word not in vocab:\n",
    "        vocab[word] = len(vocab)\n",
    "\n",
    "rev_vocab = {idx: word for word, idx in vocab.items()}\n",
    "vocab_size = len(vocab)\n",
    "print(\"Vocab size:\", vocab_size)\n",
    "\n",
    "# Save vocab\n",
    "with open(VOCAB_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    for word, idx in vocab.items():\n",
    "        f.write(f\"{word}\\t{idx}\\n\")\n",
    "print(\"Vocabulary saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46f46cbc-6725-4de5-bc66-4e56c7412423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data pairs saved!\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# Cell 8: Save data pairs\n",
    "# ------------------------------\n",
    "with open(DATA_PAIRS_PATH, \"wb\") as f:\n",
    "    pickle.dump(data_pairs, f)\n",
    "print(\"Data pairs saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5af69837-fedf-47a8-819d-136a4caa4708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Cell 9: Dataset & DataLoader\n",
    "# ------------------------------\n",
    "class HindiSpellDataset(Dataset):\n",
    "    def __init__(self, pairs, vocab):\n",
    "        self.pairs = pairs\n",
    "        self.vocab = vocab\n",
    "        self.SOS = vocab[SOS]\n",
    "        self.EOS = vocab[EOS]\n",
    "        self.UNK = vocab[UNK]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src, tgt = self.pairs[idx]\n",
    "        src_ids = [self.vocab.get(w, self.UNK) for w in src.split()] + [self.EOS]\n",
    "        tgt_ids = [self.SOS] + [self.vocab.get(w, self.UNK) for w in tgt.split()] + [self.EOS]\n",
    "        return torch.tensor(src_ids, dtype=torch.long), torch.tensor(tgt_ids, dtype=torch.long)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    PAD_IDX = vocab[PAD]\n",
    "    src_batch, tgt_batch = zip(*batch)\n",
    "    src_max = max(len(s) for s in src_batch)\n",
    "    tgt_max = max(len(t) for t in tgt_batch)\n",
    "    src_padded = torch.full((len(batch), src_max), PAD_IDX, dtype=torch.long)\n",
    "    tgt_padded = torch.full((len(batch), tgt_max), PAD_IDX, dtype=torch.long)\n",
    "    src_lengths = []\n",
    "    tgt_lengths = []\n",
    "    for i, (s, t) in enumerate(zip(src_batch, tgt_batch)):\n",
    "        src_padded[i, :len(s)] = s\n",
    "        tgt_padded[i, :len(t)] = t\n",
    "        src_lengths.append(len(s))\n",
    "        tgt_lengths.append(len(t))\n",
    "    return src_padded, tgt_padded, torch.tensor(src_lengths), torch.tensor(tgt_lengths)\n",
    "\n",
    "def make_dataloader(pairs, batch_size=16, shuffle=True):\n",
    "    dataset = HindiSpellDataset(pairs, vocab)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=collate_fn,\n",
    "                        num_workers=0, pin_memory=(device.type==\"cuda\"))\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c7bcf29-7b4c-45aa-ac0b-6bac8ce65ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 50000 sentence pairs (subset)\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# Cell 10: Subsample dataset for laptop training\n",
    "# ------------------------------\n",
    "TRAIN_SUBSET = 50_000\n",
    "if len(data_pairs) > TRAIN_SUBSET:\n",
    "    data_pairs_subset = random.sample(data_pairs, TRAIN_SUBSET)\n",
    "else:\n",
    "    data_pairs_subset = data_pairs\n",
    "\n",
    "print(f\"Training on {len(data_pairs_subset)} sentence pairs (subset)\")\n",
    "dataloader = make_dataloader(data_pairs_subset, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "868c91c2-ffec-41f7-bb78-afab613c2e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Cell 11: Model definition\n",
    "# ------------------------------\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embedded, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_out, (h, c) = self.lstm(packed)\n",
    "        out, _ = nn.utils.rnn.pad_packed_sequence(packed_out, batch_first=True)\n",
    "        return out, (h, c)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = x.unsqueeze(1)\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "        output = self.fc(output.squeeze(1))\n",
    "        return output, hidden\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, src_lengths, tgt, teacher_forcing_ratio=0.5):\n",
    "        batch_size = src.size(0)\n",
    "        tgt_len = tgt.size(1)\n",
    "        vocab_size = self.decoder.fc.out_features\n",
    "        outputs = torch.zeros(batch_size, tgt_len, vocab_size, device=self.device)\n",
    "\n",
    "        encoder_out, hidden = self.encoder(src, src_lengths)\n",
    "        input = tgt[:, 0]\n",
    "        for t in range(1, tgt_len):\n",
    "            output, hidden = self.decoder(input, hidden)\n",
    "            outputs[:, t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input = tgt[:, t] if teacher_force else top1\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e861582d-4f3c-47fe-97d0-3b4530731591",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sh.Pritpal Singh\\AppData\\Local\\Temp\\ipykernel_2500\\3724489151.py:17: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# Cell 12: Initialize model & optimizer\n",
    "# ------------------------------\n",
    "embed_size = 192\n",
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "dropout = 0.1\n",
    "\n",
    "encoder = Encoder(vocab_size, embed_size, hidden_size, num_layers, dropout)\n",
    "decoder = Decoder(vocab_size, embed_size, hidden_size, num_layers, dropout)\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=vocab[PAD])\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "use_amp = (device.type==\"cuda\")\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=use_amp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b94c9c72-112b-4fe5-a39e-0e049617cd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|████████████████████████████| 3125/3125 [03:29<00:00, 14.94it/s, Loss=5.4196, Batch Time=0.25s, ETA=0.0m]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Average Loss: 5.5091\n",
      "Checkpoint saved: checkpoints/seq2seq_epoch1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|████████████████████████████| 3125/3125 [03:27<00:00, 15.03it/s, Loss=5.5305, Batch Time=0.04s, ETA=0.0m]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Average Loss: 5.4761\n",
      "Checkpoint saved: checkpoints/seq2seq_epoch2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|████████████████████████████| 3125/3125 [03:25<00:00, 15.24it/s, Loss=5.2702, Batch Time=0.04s, ETA=0.0m]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Average Loss: 5.4606\n",
      "Checkpoint saved: checkpoints/seq2seq_epoch3.pt\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "## ------------------------------\n",
    "# Cell 13: Training loop (subset + gradient accumulation) (with timing & stats or tqdm)\n",
    "# ------------------------------\n",
    "\n",
    "num_epochs = 3\n",
    "max_grad_norm = 1.0\n",
    "accum_steps = 2  # simulate batch size 32\n",
    "\n",
    "model.train()\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    epoch_loss = 0.0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    batch_iterator = tqdm(enumerate(dataloader), total=len(dataloader), desc=f\"Epoch {epoch}\")\n",
    "    \n",
    "    for batch_idx, (src, tgt, src_lengths, tgt_lengths) in batch_iterator:\n",
    "        batch_start = time.time()\n",
    "        \n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "        src_lengths, tgt_lengths = src_lengths.to(device), tgt_lengths.to(device)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with torch.amp.autocast(device_type=device.type, enabled=use_amp):\n",
    "            output = model(src, src_lengths, tgt, teacher_forcing_ratio=0.5)\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[:,1:].reshape(-1, output_dim)\n",
    "            tgt_target = tgt[:,1:].reshape(-1)\n",
    "            loss = criterion(output, tgt_target) / accum_steps\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (batch_idx + 1) % accum_steps == 0:\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        epoch_loss += loss.item() * accum_steps\n",
    "        \n",
    "        batch_time = time.time() - batch_start\n",
    "        elapsed = time.time() - start_time\n",
    "        avg_batch_time = elapsed / (batch_idx + 1)\n",
    "        remaining_batches = len(dataloader) - batch_idx - 1\n",
    "        eta = remaining_batches * avg_batch_time\n",
    "        \n",
    "        batch_iterator.set_postfix({\n",
    "            \"Loss\": f\"{loss.item()*accum_steps:.4f}\",\n",
    "            \"Batch Time\": f\"{batch_time:.2f}s\",\n",
    "            \"ETA\": f\"{eta/60:.1f}m\"\n",
    "        })\n",
    "    \n",
    "    avg_loss = epoch_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch} Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    ckpt_path = f\"checkpoints/seq2seq_epoch{epoch}.pt\"\n",
    "    torch.save({\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"optimizer_state\": optimizer.state_dict(),\n",
    "        \"vocab\": vocab\n",
    "    }, ckpt_path)\n",
    "    print(f\"Checkpoint saved: {ckpt_path}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0075a959-7898-40bf-a73f-d2ddb7e5b3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder.state_dict(), 'encoder_state_dict.h5')\n",
    "torch.save(decoder.state_dict(), 'decoder_state_dict.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.9 (torch GPU)",
   "language": "python",
   "name": "torch_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
